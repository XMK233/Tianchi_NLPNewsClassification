{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7663d16-71f3-4c04-844c-c7dc22406897",
   "metadata": {},
   "source": [
    "Mamba out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5e4788-face-4a79-902f-e69714cd6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出logits形状: torch.Size([32, 14])\n"
     ]
    }
   ],
   "source": [
    "## 从\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class MambaConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=256,    # 模型维度\n",
    "        n_layer=4,      # Mamba层数\n",
    "        vocab_size=30000, # 词表大小\n",
    "        num_classes=14, # 分类类别数\n",
    "        state_dim=16,   # 状态空间维度\n",
    "        expand=2,       # 扩展因子\n",
    "        dt_rank=\"auto\", # Δ的秩\n",
    "        conv_kernel=4,  # 卷积核大小\n",
    "        # use_cuda=True,  # 是否使用CUDA加速\n",
    "    ):\n",
    "        self.d_model = d_model\n",
    "        self.n_layer = n_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_classes = num_classes\n",
    "        self.state_dim = state_dim\n",
    "        self.expand = expand\n",
    "        self.d_inner = int(self.expand * self.d_model)\n",
    "        self.dt_rank = dt_rank if dt_rank != \"auto\" else (self.d_model // 16)\n",
    "        self.conv_kernel = conv_kernel\n",
    "        # self.use_cuda = use_cuda\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    \"\"\"Mamba 核心块 (基于选择性状态空间模型)\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # 投影输入到内部维度\n",
    "        self.in_proj = nn.Linear(config.d_model, config.d_inner * 2, bias=False)\n",
    "\n",
    "        # 卷积分支\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=config.d_inner,\n",
    "            out_channels=config.d_inner,\n",
    "            kernel_size=config.conv_kernel,\n",
    "            groups=config.d_inner,\n",
    "            padding=config.conv_kernel - 1,\n",
    "        )\n",
    "\n",
    "        # 选择性SSM参数生成\n",
    "        self.x_proj = nn.Linear(config.d_inner, config.dt_rank + config.state_dim * 2, bias=False)\n",
    "        self.dt_proj = nn.Linear(config.dt_rank, config.d_inner, bias=True)\n",
    "        \n",
    "        # 状态空间参数\n",
    "        self.A = nn.Parameter(torch.arange(1, config.state_dim+1, dtype=torch.float32).repeat(config.d_inner, 1))\n",
    "        self.D = nn.Parameter(torch.ones(config.d_inner))\n",
    "\n",
    "        # 输出投影\n",
    "        self.out_proj = nn.Linear(config.d_inner, config.d_model, bias=False)\n",
    "\n",
    "        # 层归一化\n",
    "        self.norm = nn.LayerNorm(config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, d_model]\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # 投影到内部维度\n",
    "        x = self.in_proj(x)  # [batch, seq_len, d_inner*2]\n",
    "        x, z = x.chunk(2, dim=-1)  # 分割为两个分支\n",
    "        \n",
    "        # 1D卷积\n",
    "        x = rearrange(x, 'b l d -> b d l')\n",
    "        x = self.conv1d(x)[:, :, :-(self.config.conv_kernel - 1)]  # 因果卷积\n",
    "        x = rearrange(x, 'b d l -> b l d')\n",
    "        x = F.silu(x)\n",
    "        \n",
    "        # 生成选择性参数\n",
    "        params = self.x_proj(x)  # [batch, seq_len, dt_rank + 2*state_dim]\n",
    "        dt, B, C = torch.split(params, [self.config.dt_rank, self.config.state_dim, self.config.state_dim], dim=-1)\n",
    "        dt = self.dt_proj(dt)  # [batch, seq_len, d_inner]\n",
    "        \n",
    "        # 离散化状态空间模型\n",
    "        A = -torch.exp(self.A.float())  # [d_inner, state_dim]\n",
    "        discrete_A = torch.exp(A[None, None, :, :] * dt[:, :, :, None])  # [batch, seq_len, d_inner, state_dim]\n",
    "        discrete_B = dt[:, :, :, None] * B[:, :, None, :]  # [batch, seq_len, d_inner, state_dim]\n",
    "        C = C[:, :, None, :]  # [batch, seq_len, 1, state_dim]\n",
    "        \n",
    "        # 扫描过程 (简化实现)\n",
    "        state = torch.zeros(x.size(0), self.config.d_inner, self.config.state_dim, device=x.device)\n",
    "        outputs = []\n",
    "        for i in range(x.size(1)):\n",
    "            state = discrete_A[:, i] * state + discrete_B[:, i] * x[:, i, :, None]\n",
    "            y = (state @ C[:, i].transpose(-1, -2)).squeeze(-1) + self.D * x[:, i]\n",
    "            outputs.append(y)\n",
    "        x = torch.stack(outputs, dim=1)  # [batch, seq_len, d_inner]\n",
    "        \n",
    "        # 门控分支\n",
    "        z = torch.sigmoid(z)\n",
    "        x = x * z\n",
    "        \n",
    "        # 输出投影\n",
    "        x = self.out_proj(x)  # [batch, seq_len, d_model]\n",
    "        \n",
    "        return x + residual\n",
    "\n",
    "class MambaTextClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.d_model)\n",
    "        \n",
    "        # Mamba层堆叠\n",
    "        self.layers = nn.ModuleList([\n",
    "            MambaBlock(config) for _ in range(config.n_layer)\n",
    "        ])\n",
    "        \n",
    "        # 分类头\n",
    "        self.classifier = nn.Linear(config.d_model, config.num_classes)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: [batch, seq_len]\n",
    "        x = self.embedding(input_ids)  # [batch, seq_len, d_model]\n",
    "        \n",
    "        # 通过Mamba层\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # 池化取平均\n",
    "        pooled = x.mean(dim=1)  # [batch, d_model]\n",
    "        \n",
    "        # 分类\n",
    "        logits = self.classifier(pooled)  # [batch, num_classes]\n",
    "        return logits\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    config = MambaConfig(\n",
    "        vocab_size=30000,\n",
    "        num_classes=14,\n",
    "        d_model=256,\n",
    "        n_layer=4\n",
    "    )\n",
    "    \n",
    "    model = MambaTextClassifier(config)\n",
    "    model.to(torch.device(\"mps\"))\n",
    "    \n",
    "    # 模拟输入\n",
    "    batch_size = 32\n",
    "    seq_len = 128\n",
    "    input_ids = torch.randint(0, 30000, (batch_size, seq_len)).to(torch.device(\"mps\"))\n",
    "    \n",
    "    # 前向传播\n",
    "    logits = model(input_ids)\n",
    "    print(\"输出logits形状:\", logits.shape)  # 应为 [32, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea53d-c6f2-4ce4-bc05-df3c5d23c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
