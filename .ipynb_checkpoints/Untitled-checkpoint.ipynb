{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e617ec-5093-4d47-845e-682714605376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c442772-2021-48ad-9782-dfd134330232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321ed4d-0561-402c-8685-6bd6feaef6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028061a-4e73-4942-84b9-4af28d46fa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09f182-9a33-4907-8b78-5842ef424978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fbc141-b322-45cb-a464-f610d804636b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071a6b9d-29b6-49a7-806a-fcfd3d661c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_\n",
    " \n",
    " \n",
    "class MyData(data_.Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        tuple_ = (self.data[idx], self.label[idx])\n",
    "        return tuple_\n",
    " \n",
    " \n",
    "def collate_fn(data_tuple):   # data_tuple是一个列表，列表中包含batchsize个元组，每个元组中包含数据和标签\n",
    "    data_tuple.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    data = [sq[0] for sq in data_tuple]\n",
    "    label = [sq[1] for sq in data_tuple]\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = rnn_utils.pad_sequence(data, batch_first=True, padding_value=0.0)     # 用零补充，使长度对齐\n",
    "    label = rnn_utils.pad_sequence(label, batch_first=True, padding_value=0.0)   # 这行代码只是为了把列表变为tensor\n",
    "    return data.unsqueeze(-1), label, data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83c0c75-a875-48aa-b984-76f294377afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 2\n",
    "batchsize = 3\n",
    "hiddensize = 4\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 训练数据\n",
    "train_x = [torch.FloatTensor([1, 1, 1, 1, 1, 1, 1]),\n",
    "           torch.FloatTensor([2, 2, 2, 2, 2, 2]),\n",
    "           torch.FloatTensor([3, 3, 3, 3, 3]),\n",
    "           torch.FloatTensor([4, 4, 4, 4]),\n",
    "           torch.FloatTensor([5, 5, 5]),\n",
    "           torch.FloatTensor([6, 6]),\n",
    "           torch.FloatTensor([7])]\n",
    "# 标签\n",
    "train_y = [torch.rand(7, hiddensize),\n",
    "           torch.rand(6, hiddensize),\n",
    "           torch.rand(5, hiddensize),\n",
    "           torch.rand(4, hiddensize),\n",
    "           torch.rand(3, hiddensize),\n",
    "           torch.rand(2, hiddensize),\n",
    "           torch.rand(1, hiddensize)]\n",
    "\n",
    "data_ = MyData(train_x, train_y)\n",
    "data_loader = DataLoader(data_, batch_size=batchsize, shuffle=True, collate_fn=collate_fn)\n",
    "net = nn.LSTM(input_size=1, hidden_size=hiddensize, num_layers=num_layers, batch_first=True)\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b015bb04-480c-4252-9d66-cb501fb0cc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0131, -0.0433,  0.1516, -0.1047],\n",
       "        [-0.0114, -0.0495,  0.2033, -0.1404],\n",
       "        [-0.0101, -0.0510,  0.2173, -0.1532]], grad_fn=<CatBackward0>), batch_sizes=tensor([1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5314145-31df-4eee-84c0-4743444bd193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603c3c2-2aec-4da0-b7eb-3c68d33db0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c25dc5-aaea-4a6f-9196-5577bd809098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss:0.1775\n",
      "epoch: 0, batch_id: 1, loss:0.2362\n",
      "epoch: 0, batch_id: 2, loss:0.3314\n",
      "epoch: 1, batch_id: 0, loss:0.2086\n",
      "epoch: 1, batch_id: 1, loss:0.2058\n",
      "epoch: 1, batch_id: 2, loss:0.2842\n"
     ]
    }
   ],
   "source": [
    "# 训练方法一\n",
    "for epoch in range(EPOCH):\n",
    "    for batch_id, (batch_x, batch_y, batch_x_len) in enumerate(data_loader):\n",
    "        batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, batch_x_len, batch_first=True)\n",
    "        out, _ = net(batch_x_pack)   # out.data's shape (所有序列总长度, hiddensize)\n",
    "        out_pad, out_len = rnn_utils.pad_packed_sequence(out, batch_first=True)\n",
    "        loss = criteria(out_pad, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch:{:2d}, batch_id:{:2d}, loss:{:6.4f}'.format(epoch, batch_id, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62a2526-b935-4948-b36b-77bd5bda8287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5.],\n",
       "          [5.],\n",
       "          [5.]]]),\n",
       " tensor([[[0.0647, 0.9155, 0.4212, 0.3648],\n",
       "          [0.8188, 0.1348, 0.9962, 0.1549],\n",
       "          [0.0946, 0.5732, 0.7713, 0.0595]]]),\n",
       " [3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_x, batch_y, batch_x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c30241-4354-4a05-942a-4be8573ccd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[5.],\n",
       "        [5.],\n",
       "        [5.]]), batch_sizes=tensor([1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959ddde-adc4-4190-87ec-0d85c6c3f7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808474f-46e7-45f4-a5f3-31bb6f2b1b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db70c3-d41e-4a0c-9356-f716ade6eb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55396d31-346b-4d61-a796-27435890040c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c401f37f-7ece-489a-babc-93c4429df648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss:0.2258\n",
      "epoch: 0, batch_id: 1, loss:0.2900\n",
      "epoch: 0, batch_id: 2, loss:0.3578\n",
      "epoch: 1, batch_id: 0, loss:0.2721\n",
      "epoch: 1, batch_id: 1, loss:0.2389\n",
      "epoch: 1, batch_id: 2, loss:0.2762\n",
      "epoch: 0, batch_id: 0, loss:0.3338\n",
      "epoch: 0, batch_id: 1, loss:0.3378\n",
      "epoch: 0, batch_id: 2, loss:0.3460\n",
      "epoch: 1, batch_id: 0, loss:0.3351\n",
      "epoch: 1, batch_id: 1, loss:0.3274\n",
      "epoch: 1, batch_id: 2, loss:0.3492\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "# 训练方法二\n",
    "for epoch in range(EPOCH):\n",
    "    for batch_id, (batch_x, batch_y, batch_x_len) in enumerate(data_loader):\n",
    "        batch_x_pack = rnn_utils.pack_padded_sequence(batch_x, batch_x_len, batch_first=True)\n",
    "        batch_y_pack = rnn_utils.pack_padded_sequence(batch_y, batch_x_len, batch_first=True)\n",
    "        out, _ = net(batch_x_pack)   # out.data's shape (所有序列总长度, hiddensize)\n",
    "        loss = criteria(out.data, batch_y_pack.data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch:{:2d}, batch_id:{:2d}, loss:{:6.4f}'.format(epoch, batch_id, loss))\n",
    "\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63140462-71c9-4551-9b15-cb42b9b7d08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
