{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8114b5-ffbc-4b0a-9e85-4c007576f1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from kaitoupao import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85fbf8-6949-4d26-a614-27ae9f1ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b2f47-d25d-4943-b794-5865c4a8ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151910d0-6c8d-423f-87bc-538f48073940",
   "metadata": {},
   "source": [
    "# 加载训练集和测试集，将全量字符列表给它弄出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80519151-9c80-4bbe-8967-ca9b9d9952af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(create_originalData_path(\"train_set.csv\"), sep=\"\\t\")\n",
    "data_test = pd.read_csv(create_originalData_path(\"test_a.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003ef74-4ad9-435f-9234-516e9f608f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826656af-6b7b-4e48-85b0-eab08e20ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_class = data_train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26dc22-a3a8-40fe-967a-9b7086e7a362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae440d3-e3d2-4907-ac77-0d97962c576a",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123d3a0-63ad-4991-af25-51fceabb302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.att(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab05aa-f9ba-4ce2-b1d4-4d5b0725fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(nn.Module):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Embedding(maxlen, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        maxlen = x.size(1)\n",
    "        positions = torch.arange(0, maxlen, device=x.device).unsqueeze(0).expand_as(x)\n",
    "        return self.token_emb(x) + self.pos_emb(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983b98b-75ee-45cc-82c3-d3414861cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, num_heads, ff_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(embed_dim, 20)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.Linear(20, type_of_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        x = self.embedding_layer(x).transpose(0, 1)  # Transformer expects (seq_len, batch_size, embed_dim)\n",
    "        x = self.transformer_block(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.global_avg_pool(x.permute(0, 2, 1)).squeeze(-1)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return F.log_softmax(self.dense2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58431e00-011a-4a70-8e2f-833655d096fd",
   "metadata": {},
   "source": [
    "# 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605d765-b333-41cc-9da7-928a2eb80d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf69392-0e97-44a4-8998-2f20f1194648",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(data_train.text, data_train.label, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff91332-cb13-41d5-8f4c-e3fbe8d0d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据并进行预处理\n",
    "vocab_size = 8000  # 只考虑前 20k 词汇\n",
    "maxlen = 400  # 只考虑每条评论的前 200 个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1781011-bcb8-4bd0-9118-ea0b0fca8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_str_2_int(seq, len_lim = maxlen):\n",
    "    rst = [int(wd) for idx, wd in enumerate(seq.strip().split()) if idx < len_lim]\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b49d42-85e7-41ab-bd4a-558653d9467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in x_train]\n",
    "y_train = torch.tensor(list(y_train), dtype=torch.long)\n",
    "x_valid = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in x_valid]\n",
    "y_valid = torch.tensor(list(y_valid), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397ace3-4514-467e-87c1-f558cc6d1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequence(x_train, batch_first=True, padding_value=0)\n",
    "x_valid = pad_sequence(x_valid, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d81323-fe26-4b13-a291-f3b2cbb24901",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa2128-17f3-4aa5-b03c-4ccee003edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5ac65-4600-4003-a62c-e8c5871b219a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef87470-4ffd-4399-8160-683f5c0720ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oot = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in data_test.text]\n",
    "\n",
    "x_oot = pad_sequence(x_oot, batch_first=True, padding_value=0)\n",
    "\n",
    "oot_dataset = TensorDataset(x_oot,)\n",
    "\n",
    "oot_loader = DataLoader(oot_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553712c-babe-4b12-8257-0902ded0268c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f235d8db-587a-4b35-aad6-8286995d73b2",
   "metadata": {},
   "source": [
    "# 构建模型以及训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b3ae4-c7db-48aa-9b53-803138555eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(maxlen, vocab_size, embed_dim=64, num_heads=4, ff_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873c185-c9bc-4c08-9f4d-257022f104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ce043-bef9-4240-9f2c-4801a077760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估模型\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=2):\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, targets in tqdm.tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss/len(train_loader)}, Accuracy: {100.*correct/total}%')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            total_predicted = []\n",
    "            total_label = []\n",
    "            for inputs, targets in tqdm.tqdm(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                total_predicted += list(predicted)\n",
    "                total_label += list(targets)\n",
    "        f1 = f1_score(total_label, total_predicted, average='macro')\n",
    "                \n",
    "        print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100.*correct/total}%, f1 score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b789c8-0cf8-4e0d-897d-b42c874d11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fa936-d26b-45e5-8080-5801fd81c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe3c44-ea12-4b15-ac3f-a6eaf1e334c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d5350-dc83-41f7-a4a1-33b72dcae369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6ef7b-2814-44f5-b825-49f11c901b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5564b20-6245-4169-a865-77f7e2ba798b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bc16e-a362-4f83-b095-53764ec0179e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e182b-c62a-44fd-afc5-97c4a1495f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e28f73fe-c05f-45fb-ac86-437d8adad664",
   "metadata": {},
   "source": [
    "# 预测一下试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a123afe-2fe4-4f8a-903b-1b24f4810a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    total_predicted = []\n",
    "    for inputs in tqdm.tqdm(oot_loader):\n",
    "        outputs = model(inputs[0])\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predicted += list(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d090f-a3bc-45f4-81f2-e85fef155296",
   "metadata": {},
   "outputs": [],
   "source": [
    "oot_rst = [int(x) for x in total_predicted]\n",
    "len(oot_rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd7c9e-be76-4c3e-89c7-beae8a4ccf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_to_newbasepath(pd.DataFrame({\"label\": oot_rst}), \"rst-20241227\", fmt=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76eb7f-745a-4d6f-907f-a738d7348734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381d884-c1b3-418d-a391-ba51d3c20df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a5ca3-21e1-466c-aeff-bbf6a4b94868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
