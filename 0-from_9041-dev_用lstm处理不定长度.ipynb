{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17369d60-106d-456e-9790-dd590dd67180",
   "metadata": {},
   "source": [
    "主要就是，扩大了 maxlen 。表现就能提高很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8114b5-ffbc-4b0a-9e85-4c007576f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/Tianchi_NLPNewsClassification\n",
      "code dir: /Users/minkexiu/Documents/GitHub/Tianchi_NLPNewsClassification \n",
      "\n",
      "19 18 44\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "本卦上：3 本卦下：2 变爻：2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>火泽睽</th>\n",
       "      <th>水火既济</th>\n",
       "      <th>火雷噬嗑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☲离火</td>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☲离火</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☱兑金</td>\n",
       "      <td>☲离火</td>\n",
       "      <td>☳震木</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    火泽睽 水火既济 火雷噬嗑\n",
       "上卦  ☲离火  ☵坎水  ☲离火\n",
       "下卦  ☱兑金  ☲离火  ☳震木"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 20 10 酉时\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "本卦上：4 本卦下：4 变爻：4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>雷雷震</th>\n",
       "      <th>水山蹇</th>\n",
       "      <th>地雷复</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☳震木</td>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☷坤土</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☳震木</td>\n",
       "      <td>☶艮土</td>\n",
       "      <td>☳震木</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    雷雷震  水山蹇  地雷复\n",
       "上卦  ☳震木  ☵坎水  ☷坤土\n",
       "下卦  ☳震木  ☶艮土  ☳震木"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from kaitoupao import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d85fbf8-6949-4d26-a614-27ae9f1ecab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319b2f47-d25d-4943-b794-5865c4a8ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151910d0-6c8d-423f-87bc-538f48073940",
   "metadata": {},
   "source": [
    "# 加载训练集和测试集，将全量字符列表给它弄出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80519151-9c80-4bbe-8967-ca9b9d9952af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(create_originalData_path(\"train_set.csv\"), sep=\"\\t\").sample(10000).reset_index(drop=True)\n",
    "data_test = pd.read_csv(create_originalData_path(\"test_a.csv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21e708b-243a-46fa-a950-ec54729fd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"data_id\"] = range(data_train.shape[0])\n",
    "data_test[\"data_id\"] = range(data_test.shape[0])\n",
    "data_test[\"label\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7003ef74-4ad9-435f-9234-516e9f608f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3), (50000, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826656af-6b7b-4e48-85b0-eab08e20ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_class = data_train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac26dc22-a3a8-40fe-967a-9b7086e7a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 10000/10000 [00:00<00:00, 46474.85it/s]\n",
      "100%|██████████████████████████████████| 50000/50000 [00:00<00:00, 64620.71it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_text_len(txt):\n",
    "    return len(txt.strip().split())\n",
    "data_train[\"txt_len\"] = data_train.text.progress_apply(get_text_len)\n",
    "data_test[\"txt_len\"] = data_test.text.progress_apply(get_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e87fe43-9d71-4948-b2b9-f0d2601db7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.sort_values(\"txt_len\").reset_index(drop=True)\n",
    "data_test = data_test.sort_values(\"txt_len\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "544c0d29-f779-4d63-8208-96ff38c32aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>data_id</th>\n",
       "      <th>txt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>3605 6357 7251 1582 5602 3370 486 5660 3327 40...</td>\n",
       "      <td>5090</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>6065 4464 486 6122 3529 6122 6127 7495 3531 68...</td>\n",
       "      <td>152</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>7059 5861 2354 1695 648 2838 4662 711 7059 586...</td>\n",
       "      <td>739</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>7328 5547 1241 4021 7539 910 619 5775 584 2465...</td>\n",
       "      <td>3136</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6832 5011 3813 5780 1913 4148 6656 6609 2465 2...</td>\n",
       "      <td>6447</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>6</td>\n",
       "      <td>2456 5589 1215 450 7539 6293 3661 6770 192 356...</td>\n",
       "      <td>4200</td>\n",
       "      <td>11255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>1580 3568 7539 6831 761 1460 1610 6644 4063 67...</td>\n",
       "      <td>6317</td>\n",
       "      <td>12460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>5036 6501 2899 4163 2465 2799 2073 3659 1324 4...</td>\n",
       "      <td>1876</td>\n",
       "      <td>14531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>2716 1970 6357 2614 7044 4853 2693 6713 62 330...</td>\n",
       "      <td>1230</td>\n",
       "      <td>14672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>5036 6501 2899 4163 2465 4464 3659 2073 6065 4...</td>\n",
       "      <td>8429</td>\n",
       "      <td>21117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  data_id  \\\n",
       "0         8  3605 6357 7251 1582 5602 3370 486 5660 3327 40...     5090   \n",
       "1         8  6065 4464 486 6122 3529 6122 6127 7495 3531 68...      152   \n",
       "2         8  7059 5861 2354 1695 648 2838 4662 711 7059 586...      739   \n",
       "3         9  7328 5547 1241 4021 7539 910 619 5775 584 2465...     3136   \n",
       "4         1  6832 5011 3813 5780 1913 4148 6656 6609 2465 2...     6447   \n",
       "...     ...                                                ...      ...   \n",
       "9995      6  2456 5589 1215 450 7539 6293 3661 6770 192 356...     4200   \n",
       "9996      0  1580 3568 7539 6831 761 1460 1610 6644 4063 67...     6317   \n",
       "9997      1  5036 6501 2899 4163 2465 2799 2073 3659 1324 4...     1876   \n",
       "9998      1  2716 1970 6357 2614 7044 4853 2693 6713 62 330...     1230   \n",
       "9999      1  5036 6501 2899 4163 2465 4464 3659 2073 6065 4...     8429   \n",
       "\n",
       "      txt_len  \n",
       "0          15  \n",
       "1          16  \n",
       "2          17  \n",
       "3          17  \n",
       "4          19  \n",
       "...       ...  \n",
       "9995    11255  \n",
       "9996    12460  \n",
       "9997    14531  \n",
       "9998    14672  \n",
       "9999    21117  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c92664-9004-4ef0-aafe-82a27c1953f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>data_id</th>\n",
       "      <th>label</th>\n",
       "      <th>txt_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3366 6407 932 2848 2400 3870 3242 2685 4490 42...</td>\n",
       "      <td>5081</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1141 473 1407 4802 7539 3961 1227 2380 5689 68...</td>\n",
       "      <td>39409</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2289 6357 2109 4139 248 3193 4595 1148 3397 30...</td>\n",
       "      <td>649</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3945 7444 2109 4139 5122 4148 2490 4811 5612 3...</td>\n",
       "      <td>22985</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5041 1877 1241 5702 736 2396 2465 2210 6040 22...</td>\n",
       "      <td>18530</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>299 6357 151 2859 1866 7495 3961 1227 5860 121...</td>\n",
       "      <td>5558</td>\n",
       "      <td>-1</td>\n",
       "      <td>38588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>3700 2073 4464 3700 4853 299 6357 151 2859 584...</td>\n",
       "      <td>9236</td>\n",
       "      <td>-1</td>\n",
       "      <td>38906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>4646 2073 4464 4853 299 6357 151 2859 584 1920...</td>\n",
       "      <td>19746</td>\n",
       "      <td>-1</td>\n",
       "      <td>38930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>4516 5264 299 6357 151 2859 62 3300 5491 4464 ...</td>\n",
       "      <td>15053</td>\n",
       "      <td>-1</td>\n",
       "      <td>41459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>5036 6501 2899 4163 2465 4464 4464 2073 4464 2...</td>\n",
       "      <td>40475</td>\n",
       "      <td>-1</td>\n",
       "      <td>41861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  data_id  label  \\\n",
       "0      3366 6407 932 2848 2400 3870 3242 2685 4490 42...     5081     -1   \n",
       "1      1141 473 1407 4802 7539 3961 1227 2380 5689 68...    39409     -1   \n",
       "2      2289 6357 2109 4139 248 3193 4595 1148 3397 30...      649     -1   \n",
       "3      3945 7444 2109 4139 5122 4148 2490 4811 5612 3...    22985     -1   \n",
       "4      5041 1877 1241 5702 736 2396 2465 2210 6040 22...    18530     -1   \n",
       "...                                                  ...      ...    ...   \n",
       "49995  299 6357 151 2859 1866 7495 3961 1227 5860 121...     5558     -1   \n",
       "49996  3700 2073 4464 3700 4853 299 6357 151 2859 584...     9236     -1   \n",
       "49997  4646 2073 4464 4853 299 6357 151 2859 584 1920...    19746     -1   \n",
       "49998  4516 5264 299 6357 151 2859 62 3300 5491 4464 ...    15053     -1   \n",
       "49999  5036 6501 2899 4163 2465 4464 4464 2073 4464 2...    40475     -1   \n",
       "\n",
       "       txt_len  \n",
       "0           14  \n",
       "1           14  \n",
       "2           14  \n",
       "3           15  \n",
       "4           17  \n",
       "...        ...  \n",
       "49995    38588  \n",
       "49996    38906  \n",
       "49997    38930  \n",
       "49998    41459  \n",
       "49999    41861  \n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf55b6e-ea9f-4ab8-b382-ef64689944b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae440d3-e3d2-4907-ac77-0d97962c576a",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a123d3a0-63ad-4991-af25-51fceabb302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.att(x, x, x)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ab05aa-f9ba-4ce2-b1d4-4d5b0725fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.lstm_emb = nn.LSTM(input_size=embed_dim, hidden_size=embed_dim, num_layers=2, batch_first=True)\n",
    "        # self.gru_emb = nn.GRU(input_size=embed_dim, hidden_size=embed_dim, num_layers=2, batch_first=True)\n",
    "        \n",
    "        self.pos_emb = nn.Embedding(5, embed_dim) ## 这个10是根据 self.lstm_emb，self.gru_emb 算出来的。\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb_here = torch.squeeze(\n",
    "            self.token_emb(x)\n",
    "        )\n",
    "        \n",
    "        out1, _1 = self.lstm_emb(emb_here)\n",
    "        lstm_part = torch.cat([\n",
    "            _1[0].permute(1, 0, 2), ## h_t；总共2层，层数取决于初始化的层数。\n",
    "            _1[1].permute(1, 0, 2), ## c_t；总共2层，层数取决于初始化的层数。\n",
    "            torch.mean(out1, dim=1).unsqueeze(1) ## output，把每一个输入对应的输出，给它平均一下。共1层。\n",
    "        ], dim=1)\n",
    "        ## there are 5 seq_lens. \n",
    "\n",
    "        # out2, _2 = self.gru_emb(emb_here)\n",
    "        # gru_part = torch.cat([\n",
    "        #     _2[0].permute(1, 0, 2), \n",
    "        #     _2[1].permute(1, 0, 2),\n",
    "        #     torch.mean(out2, dim=1).unsqueeze(1)\n",
    "        # ], dim=1)\n",
    "        # ## there are 5 seq_lens. \n",
    "\n",
    "        seq_part = lstm_part\n",
    "        # torch.cat([\n",
    "        #     lstm_part, gru_part\n",
    "        # ], dim=1)\n",
    "        # ## in total, there are 5 seq_lens. \n",
    "\n",
    "        positions = torch.arange(0, 5, device=x.device).unsqueeze(0).expand(x.shape[0], 5)\n",
    "        \n",
    "        return seq_part + self.pos_emb(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7983b98b-75ee-45cc-82c3-d3414861cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, num_heads, ff_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(vocab_size, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(embed_dim, 20)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dense2 = nn.Linear(20, type_of_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        x = self.embedding_layer(x).transpose(0, 1)  # Transformer expects (seq_len, batch_size, embed_dim)\n",
    "        x = self.transformer_block(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.global_avg_pool(x.permute(0, 2, 1)).squeeze(-1)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return F.log_softmax(self.dense2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58431e00-011a-4a70-8e2f-833655d096fd",
   "metadata": {},
   "source": [
    "# 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1522f996-b5b5-43dd-addf-c69901653852",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 【TODO】\n",
    "## https://www.cnblogs.com/picassooo/p/13577527.html 尝试一下 https://blog.csdn.net/xinjieyuan/article/details/108562360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6605d765-b333-41cc-9da7-928a2eb80d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf69392-0e97-44a4-8998-2f20f1194648",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ori, valid_ori = train_test_split(data_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8ddfe6-397c-45cd-b4f9-d83c667e2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ori.reset_index(drop=True, inplace=True)\n",
    "valid_ori.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e5e5f-05a0-46e6-8c4c-a91daa57b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ff91332-cb13-41d5-8f4c-e3fbe8d0d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据并进行预处理\n",
    "vocab_size = 8000  # 只考虑前 20k 词汇\n",
    "maxlen = 800  # 只考虑每条评论的前 200 个词\n",
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1781011-bcb8-4bd0-9118-ea0b0fca8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seq_str_2_int(seq, len_lim = maxlen):\n",
    "    rst = [int(wd) for idx, wd in enumerate(seq.strip().split())]\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc78ba32-2afa-49c8-80be-68a1dbee516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in train_ori.text]\n",
    "y_train = torch.tensor(list(train_ori.label), dtype=torch.long)\n",
    "id_train = torch.tensor(list(train_ori.data_id), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b08f15-f386-4962-bbe3-0055ad9d9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in valid_ori.text]\n",
    "y_valid = torch.tensor(list(valid_ori.label), dtype=torch.long)\n",
    "id_valid = torch.tensor(list(valid_ori.data_id), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddaae433-21aa-49f9-adf8-c0556658324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, data, label, data_id):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.data_id = data_id\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        tuple_ = (self.data[idx], self.label[idx], self.data_id[idx])\n",
    "        return tuple_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0846ba4-cc76-4b35-a2c2-d5f357f133ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data_tuple):   # data_tuple是一个列表，列表中包含batchsize个元组，每个元组中包含数据和标签\n",
    "    data_tuple.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    data = [sq[0] for sq in data_tuple]\n",
    "    label = [sq[1] for sq in data_tuple]\n",
    "    data_id = [sq[2] for sq in data_tuple]\n",
    "    data_length = [len(sq) for sq in data]\n",
    "    data = pad_sequence(data, batch_first=True, padding_value=0.0)     # 用零补充，使长度对齐\n",
    "    label = torch.tensor(label, dtype=torch.long) # pad_sequence(label, batch_first=True, padding_value=0.0)   # 这行代码只是为了把列表变为tensor\n",
    "    return data.unsqueeze(-1), label, data_length, data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e690851-225d-4fa4-8e4f-cd96363e5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyData(x_train, y_train, id_train)\n",
    "val_dataset = MyData(x_valid, y_valid, id_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b49ca57-3141-4f15-892d-da875b9a072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b553712c-babe-4b12-8257-0902ded0268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_oot = [torch.tensor(preprocess_seq_str_2_int(seq), dtype=torch.long) for seq in data_test.text]\n",
    "y_oot = torch.tensor(list(data_test.label), dtype=torch.long)\n",
    "id_oot = torch.tensor(list(data_test.data_id), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ad26507-a73f-4f84-9386-9c6fa237878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oot_dataset = MyData(x_oot, y_oot, id_oot)\n",
    "oot_loader = DataLoader(oot_dataset, batch_size=batchsize, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8c942-2beb-466b-95a6-93997923c8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cbab669-fb1a-499c-b45a-670c83656433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_loader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a31e34-1c07-4210-b646-72de3d29e090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f235d8db-587a-4b35-aad6-8286995d73b2",
   "metadata": {},
   "source": [
    "# 构建模型以及训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7f09d1a-8a31-44ad-900d-e35c562d8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(maxlen, vocab_size, embed_dim=8, num_heads=2, ff_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a229038-2009-4279-ad6d-78bb9fde3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding_layer): TokenAndPositionEmbedding(\n",
       "    (token_emb): Embedding(8000, 8)\n",
       "    (lstm_emb): LSTM(8, 8, num_layers=2, batch_first=True)\n",
       "    (pos_emb): Embedding(5, 8)\n",
       "  )\n",
       "  (transformer_block): TransformerBlock(\n",
       "    (att): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "    )\n",
       "    (layernorm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "    (layernorm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dense1): Linear(in_features=8, out_features=20, bias=True)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dense2): Linear(in_features=20, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a1d6b-af18-4a14-a5b2-5c450b0328a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8a5db8fe-ff69-4746-bb05-5a40038f5c10",
   "metadata": {},
   "source": [
    "model.to(device)\n",
    "    \n",
    "# for epoch in range(1):\n",
    "\n",
    "model.train()\n",
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "for inputs, targets, d_l, d_id in tqdm.tqdm(train_loader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.requires_grad_(True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += predicted.eq(targets).sum().item()\n",
    "print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss/len(train_loader)}, Accuracy: {100.*correct/total}%')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12b7d686-5178-4e0b-9f21-c8e0821fd4f5",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    total_predicted = []\n",
    "    total_label = []\n",
    "    for inputs, targets, d_l, d_id in tqdm.tqdm(val_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        total_predicted += list(predicted)\n",
    "        total_label += list(targets)\n",
    "f1 = f1_score(total_label, total_predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05155c-8366-4e30-a36c-3fcd499a3cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be7ce043-bef9-4240-9f2c-4801a077760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估模型\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=2):\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, targets, d_l, d_id in tqdm.tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss/len(train_loader)}, Accuracy: {100.*correct/total}%')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            total_predicted = []\n",
    "            total_label = []\n",
    "            for inputs, targets, d_l, d_id in tqdm.tqdm(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                total_predicted += list(predicted.cpu())\n",
    "                total_label += list(targets.cpu())\n",
    "        f1 = f1_score(total_label, total_predicted, average='macro')\n",
    "                \n",
    "        print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100.*correct/total}%, f1 score is {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38b789c8-0cf8-4e0d-897d-b42c874d11ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 438/438 [01:15<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 2.2797262823744995, Accuracy: 18.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188/188 [00:15<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2567162076209453, Accuracy: 18.933333333333334%, f1 score is 0.02873197889947538\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e60fa936-d26b-45e5-8080-5801fd81c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 438/438 [01:11<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.275156504215171, Accuracy: 19.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188/188 [00:13<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.253585273915149, Accuracy: 19.366666666666667%, f1 score is 0.02317788327282882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 438/438 [01:08<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 2.2719187379972032, Accuracy: 19.385714285714286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188/188 [00:11<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.250050844030177, Accuracy: 19.366666666666667%, f1 score is 0.02317788327282882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 438/438 [01:05<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 2.271122164377883, Accuracy: 19.385714285714286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188/188 [00:10<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.250664326738804, Accuracy: 19.3%, f1 score is 0.030914382904184873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 438/438 [01:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 2.2726994712058812, Accuracy: 19.485714285714284%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 188/188 [00:09<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.251068541978268, Accuracy: 18.9%, f1 score is 0.028833935615694778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▎                      | 195/438 [00:28<00:36,  6.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Transformer expects (seq_len, batch_size, embed_dim)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_block(x)\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mTokenAndPositionEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     emb_here \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_emb(x)\n\u001b[1;32m     14\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0m     out1, _1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_here\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     lstm_part \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     18\u001b[0m         _1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;66;03m## h_t；总共2层，层数取决于初始化的层数。\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         _1[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;66;03m## c_t；总共2层，层数取决于初始化的层数。\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         torch\u001b[38;5;241m.\u001b[39mmean(out1, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m## output，把每一个输入对应的输出，给它平均一下。共1层。\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m## there are 5 seq_lens. \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# out2, _2 = self.gru_emb(emb_here)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# ], dim=1)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# ## there are 5 seq_lens. \u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe3c44-ea12-4b15-ac3f-a6eaf1e334c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d5350-dc83-41f7-a4a1-33b72dcae369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6ef7b-2814-44f5-b825-49f11c901b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5564b20-6245-4169-a865-77f7e2ba798b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bc16e-a362-4f83-b095-53764ec0179e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e182b-c62a-44fd-afc5-97c4a1495f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e28f73fe-c05f-45fb-ac86-437d8adad664",
   "metadata": {},
   "source": [
    "# 预测一下试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a123afe-2fe4-4f8a-903b-1b24f4810a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    total_predicted = []\n",
    "    for inputs, targets, d_l, d_id in tqdm.tqdm(oot_loader):\n",
    "        outputs = model(inputs[0])\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predicted += list(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d090f-a3bc-45f4-81f2-e85fef155296",
   "metadata": {},
   "outputs": [],
   "source": [
    "oot_rst = [int(x) for x in total_predicted]\n",
    "len(oot_rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd7c9e-be76-4c3e-89c7-beae8a4ccf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_to_newbasepath(pd.DataFrame({\"label\": oot_rst}), \"rst-20250104_2\", fmt=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76eb7f-745a-4d6f-907f-a738d7348734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381d884-c1b3-418d-a391-ba51d3c20df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a5ca3-21e1-466c-aeff-bbf6a4b94868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
